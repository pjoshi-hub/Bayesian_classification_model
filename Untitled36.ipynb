{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Prasoon\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n"
     ]
    }
   ],
   "source": [
    "import statsmodels.api as sm\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import glob\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "import random\n",
    "from collections import Counter\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.utils import shuffle\n",
    "sns.set_style('whitegrid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "r = np.random.randint(500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def type_wise_results(dict_numtest_samples,y_test,arr_pred_test,aleatoric_uncertainty,epistemic_uncertainty):\n",
    "    dict_result = {}\n",
    "    temp_prev = 0\n",
    "    list_accuracy = []\n",
    "    for i in range(31):\n",
    "        temp = dict_numtest_samples[i]\n",
    "        sliced_y_pred = arr_pred_test[temp_prev:temp_prev+temp]\n",
    "        sliced_y_test = y_test[temp_prev:temp_prev+temp]\n",
    "        al_uncertainty_test = aleatoric_uncertainty[temp_prev:temp_prev+temp]\n",
    "        ep_uncertainty_test = epistemic_uncertainty[temp_prev:temp_prev+temp]\n",
    "        dict_result[i] = [sliced_y_test,sliced_y_pred,al_uncertainty_test,ep_uncertainty_test]\n",
    "        temp_prev = temp_prev+temp\n",
    "    return dict_result\n",
    "\n",
    "\n",
    "\n",
    "def placeholders(n_x,n_y):\n",
    "    X = tf.placeholder(tf.float32,shape=[n_x,None],name='X')\n",
    "    Y = tf.placeholder(tf.float32,shape=[n_y,None],name='Y')\n",
    "    return (X,Y)\n",
    "\n",
    "\n",
    "def forward_propagation(X,layers_dims,param_normal, keep_prob=1.0):\n",
    "    \n",
    "    def sample_epsilons(param_normal):\n",
    "        epsilons_W = []\n",
    "        epsilons_b = []\n",
    "        for i in range(len(layers_dims)-1):\n",
    "            epsilons_W.append(tf.random_normal(shape=tf.shape(param_normal[\"mu_W\"+str(i+1)]), mean=0., stddev=1.0))\n",
    "            epsilons_b.append(tf.random_normal(shape=tf.shape(param_normal[\"mu_b\"+str(i+1)]), mean=0., stddev=1.0))\n",
    "        return epsilons_W,epsilons_b\n",
    "\n",
    "    def transform_rhos(layers_dims,param_normal):\n",
    "        for i in range(len(layers_dims)-1):\n",
    "            param_normal[\"rho_W\"+str(i+1)] = softplus(param_normal[\"rho_W\"+str(i+1)])\n",
    "            param_normal[\"rho_b\"+str(i+1)] = softplus(param_normal[\"rho_b\"+str(i+1)])\n",
    "        return param_normal\n",
    "\n",
    "    def make_gaussian_samples(param_normal,layers_dims,epsilons_W,epsilons_b):\n",
    "        samples_W = []\n",
    "        samples_b = []\n",
    "        for i in range(len(layers_dims)-1):\n",
    "            samples_W.append(tf.add(param_normal[\"mu_W\"+str(i+1)],tf.multiply( param_normal[\"rho_W\"+str(i+1)] , epsilons_W[i])))\n",
    "            samples_b.append(tf.add(param_normal[\"mu_b\"+str(i+1)] ,tf.multiply( param_normal[\"rho_b\"+str(i+1)] , epsilons_b[i])))\n",
    "        return samples_W, samples_b\n",
    "\n",
    "    epsilons_W,epsilons_b = sample_epsilons(param_normal)\n",
    "    param_normal = transform_rhos(layers_dims,param_normal)\n",
    "    samples_W, samples_b =  make_gaussian_samples(param_normal,layers_dims,epsilons_W,epsilons_b)\n",
    "    \n",
    "    store = {}\n",
    "    store['A0'] = X\n",
    "    for l in range(len(layers_dims)-1):\n",
    "        store[\"Z\"+str(l+1)] = tf.add(tf.matmul(samples_W[l],store[\"A\"+str(l)]),samples_b[l])\n",
    "        if (l == len(layers_dims) - 2):\n",
    "            return store[\"Z\"+str(l+1)],samples_W,samples_b\n",
    "        store[\"A\"+str(l+1)] = tf.nn.sigmoid(store[\"Z\"+str(l+1)])\n",
    "        store[\"A\"+str(l+1)] = tf.nn.dropout(store[\"A\"+str(l+1)], keep_prob)\n",
    "\n",
    "\n",
    "def initialization(layers_dims):\n",
    "    param_normal = {}\n",
    "    for l in range(len(layers_dims)-1):\n",
    "        param_normal[\"mu_W\"+str(l+1)] = tf.get_variable('mu_W'+str(l+1),[layers_dims[l+1],layers_dims[l]],initializer =  tf.random_normal_initializer(mean = 0.0,stddev = 0.1))\n",
    "        param_normal[\"rho_W\"+str(l+1)] = -15.5 + tf.get_variable(\"rho_W\"+str(l+1),[layers_dims[l+1],layers_dims[l]],initializer = tf.zeros_initializer())\n",
    "        param_normal[\"mu_b\"+str(l+1)] = tf.get_variable('mu_b'+str(l+1),[layers_dims[l+1],1],initializer =  tf.random_normal_initializer(mean = 0.0,stddev = 0.1))\n",
    "        param_normal[\"rho_b\"+str(l+1)] =  -16.5 + tf.get_variable(\"rho_b\"+str(l+1),[layers_dims[l+1],1],initializer = tf.zeros_initializer())\n",
    "    return param_normal \n",
    "\n",
    "\n",
    "def softplus(x):\n",
    "    return tf.log(1.0 + tf.exp(x))\n",
    "\n",
    "def log_gaussian(x, mu,sigma):\n",
    "    return -0.5 * tf.log(2.0 * tf.constant(math.pi)) - tf.log(sigma) - tf.truediv(tf.multiply((x-mu),(x-mu)), (2.0 * tf.multiply(sigma,sigma)))\n",
    "\n",
    "def prior(x):\n",
    "    mean_prior = tf.constant(0.0)\n",
    "    sigma_prior = tf.constant(1.0)\n",
    "    return tf.reduce_sum(log_gaussian(x,mean_prior,sigma_prior))\n",
    "\n",
    "def gaussian(x,mu,sigma):\n",
    "    scaling = tf.truediv(1.0,tf.sqrt(2.0 * tf.constant(math.pi) * tf.multiply(sigma,sigma)))\n",
    "    bell = tf.exp(-1.0 * tf.truediv(tf.multiply((x-mu),(x-mu)), (2.0 * tf.multiply(sigma,sigma))))\n",
    "    return tf.multiply(scaling,bell)\n",
    "\n",
    "def scale_mixture_prior(x):\n",
    "    sigma_p1 = tf.constant(0.2)\n",
    "    sigma_p2 = tf.constant(0.8)\n",
    "    pi = 0.15\n",
    "    first_gaussian = tf.constant(pi) * gaussian(x,0.0,sigma_p1)\n",
    "    second_gaussian = (1.0-tf.constant(pi)) * gaussian(x,0.0,sigma_p2)\n",
    "    return tf.reduce_sum(tf.log(first_gaussian+second_gaussian))\n",
    "\n",
    "def log_softmax_likelihood(ZL, y):\n",
    "    return  -1 * tf.reduce_sum(tf.nn.softmax_cross_entropy_with_logits(labels=tf.transpose(y),logits=tf.transpose(ZL),))\n",
    "\n",
    "\n",
    "def compute_cost(layers_dims,samples_W,samples_b,param_normal,ZL,label_one_hot):\n",
    "    log_likelihood_sum = log_softmax_likelihood(ZL, label_one_hot)\n",
    "    log_prior_list = []\n",
    "    log_var_posterior_list = []\n",
    "    for i in range(len(layers_dims)-1):\n",
    "        log_prior_list.append(prior(samples_W[i]))\n",
    "        log_prior_list.append(prior(samples_b[i]))\n",
    "        log_var_posterior_list.append(tf.reduce_sum(log_gaussian(samples_W[i],param_normal[\"mu_W\"+str(i+1)],param_normal[\"rho_W\"+str(i+1)])))\n",
    "        log_var_posterior_list.append( tf.reduce_sum(log_gaussian(samples_b[i],param_normal[\"mu_b\"+str(i+1)],param_normal[\"rho_b\"+str(i+1)])))\n",
    "    log_prior_sum = sum(log_prior_list)\n",
    "    log_var_posterior_sum = sum(log_var_posterior_list)\n",
    "    return 1/(X_train.shape[1]) * (log_var_posterior_sum - log_prior_sum -  log_likelihood_sum)#log_likelihood_sum #(log_var_posterior_sum - log_prior_sum -  log_likelihood_sum)   #((log_var_posterior_sum - log_prior_sum) \n",
    "\n",
    "\n",
    "def model(X_train,Y_train,X_test,Y_test,learning_rate,num_epochs,print_cost,layers_dims):\n",
    "    tf.reset_default_graph()\n",
    "    tf.set_random_seed(1234)\n",
    "    n_x = X_train.shape[0]\n",
    "    m = X_train.shape[1]\n",
    "    n_y = Y_train.shape[0]\n",
    "    costs =[]\n",
    "    (X,Y) = placeholders(n_x,n_y)\n",
    "    param_normal = initialization(layers_dims)\n",
    "    ZL,samples_W,samples_b = forward_propagation(X,layers_dims,param_normal)\n",
    "    loss = compute_cost(layers_dims,samples_W,samples_b,param_normal,ZL,Y_train)\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate = learning_rate).minimize(loss) \n",
    "    init = tf.global_variables_initializer()\n",
    "    with tf.Session() as sess:\n",
    "        sess.run(init)\n",
    "        for epoch in range(num_epochs):\n",
    "            _,epoch_cost = sess.run([optimizer,loss],feed_dict={X : X_train, Y : Y_train})\n",
    "            if print_cost == True and epoch % 100 == 0:\n",
    "                print (\"Cost after epoch %i: %f\" % (epoch, epoch_cost))\n",
    "            if print_cost == True and epoch % 5 == 0:\n",
    "                costs.append(epoch_cost)\n",
    "        logit_final_temp = tf.nn.softmax(ZL,axis=0)\n",
    "        list_logit_train = []\n",
    "        list_logit_test = []\n",
    "        list_Z = []\n",
    "        for pred in range(0,500):\n",
    "            logit_final_test = logit_final_temp.eval(feed_dict={X: X_test})\n",
    "            logit_final_train = logit_final_temp.eval(feed_dict = {X: X_train})\n",
    "            Z = ZL.eval(feed_dict={X: X_test})\n",
    "            list_logit_train.append(logit_final_train)\n",
    "            list_logit_test.append(logit_final_test)\n",
    "            list_Z.append(Z)\n",
    "            if pred == 0:\n",
    "                arr_pred_train = np.argmax(logit_final_train, axis= 0)\n",
    "                arr_pred_test = np.argmax(logit_final_test,axis=0)\n",
    "                train_accuracy =  np.sum(arr_pred_train == Ytrain) / len(arr_pred_train)\n",
    "                test_accuracy = np.sum(arr_pred_test == Ytest) / len(arr_pred_test)\n",
    "                grad = tf.gradients(logit_final_temp,X)\n",
    "                grad_val = sess.run(grad, feed_dict = {X:X_train})\n",
    "    print(\"Train Accuracy:\", train_accuracy*100)\n",
    "    print(\"Test Accuracy:\", test_accuracy*100)\n",
    "    return [train_accuracy,test_accuracy,list_logit_test,list_logit_train,arr_pred_test,arr_pred_train,grad_val]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_label = pd.read_csv('D:/New Folder/labels.csv',header=1)\n",
    "label = list(df_label['Abbreviation'])\n",
    "\n",
    "\n",
    "def detailed_plot_new(dict_result_train,uncertainty_type,y_test,arr_pred_test,al_test,image_name,cancer_types,scal_fac=1e9):\n",
    " \n",
    "    dict_mean_train = {}\n",
    "    dict_mean_test_corr = {}\n",
    "    dict_mean_test_incorr = {}\n",
    "    for i in range(len(cancer_types)):\n",
    "    \n",
    "       \n",
    "        train = dict_result_train[i][0]\n",
    "        pred_train = dict_result_train[i][1]\n",
    "        al_train_temp = dict_result_train[i][2]\n",
    "        ep_train_temp = dict_result_train[i][3]\n",
    "        \n",
    "        \n",
    "        \n",
    "      \n",
    "        \n",
    "        list_index = list(np.where(arr_pred_test == i)[0])\n",
    "        list_index2 = list(np.where(y_test==i)[0])\n",
    "    \n",
    "        correct_index = []\n",
    "        incorrect_index = []\n",
    "        for j in range(len(list_index)):\n",
    "            if (list_index[j] in list_index2) == True:\n",
    "                correct_index.append(j)\n",
    "            else:\n",
    "                incorrect_index.append(j)\n",
    "        \n",
    "        \n",
    "        corr_al = al_test[list(np.array(list_index)[correct_index])]\n",
    "        incorr_al = al_test[list(np.array(list_index)[incorrect_index])]\n",
    "        \n",
    "       \n",
    "        list_combined = list(corr_al)+list(incorr_al)\n",
    "        \n",
    "        index_temp_incorr = []\n",
    "        index_temp = []\n",
    "        for j in range(len(list_combined)):\n",
    "            index_temp.append(j)\n",
    "            if (j >= len(corr_al)):\n",
    "                index_temp_incorr.append(j)\n",
    "        \n",
    "        \n",
    "        l_final, l_index_final = shuffle(list_combined, index_temp, random_state=0)\n",
    "        \n",
    "        \n",
    "        \n",
    "      \n",
    "        \n",
    "        incorrect = []\n",
    "        for j in range(len(l_index_final)):\n",
    "            if (l_index_final[j] in index_temp_incorr) ==True:\n",
    "                incorrect.append(j)\n",
    "        \n",
    "        \n",
    "        correct_train = []\n",
    "        incorrect_train = []\n",
    "        for k in range(len(list(pred_train))):\n",
    "            if (pred_train[k] != train[k]):\n",
    "                incorrect_train.append(k)\n",
    "            else:\n",
    "                correct_train.append(k)\n",
    "\n",
    "        if uncertainty_type == 'Aleatoric':\n",
    "\n",
    "            corr = np.mean(corr_al)\n",
    "            incorr = np.mean(incorr_al)\n",
    "            corr_train = np.mean(al_train_temp[correct_train])\n",
    "            dict_mean_train[i] = corr_train\n",
    "            dict_mean_test_corr[i] = corr\n",
    "            dict_mean_test_incorr[i] = incorr\n",
    "            \n",
    "        if uncertainty_type == 'Epistemic':\n",
    "            \n",
    "            corr = np.mean(corr_al)*scal_fac\n",
    "            incorr = np.mean(incorr_al)*scal_fac\n",
    "            corr_train = np.mean(ep_train_temp[correct_train])*scal_fac\n",
    "            dict_mean_train[i] = corr_train\n",
    "            dict_mean_test_corr[i] = corr\n",
    "            dict_mean_test_incorr[i] = incorr\n",
    "            \n",
    "       \n",
    "    return dict_mean_train,dict_mean_test_corr,dict_mean_test_incorr\n",
    "\n",
    "\n",
    "def uncertainty_calculation(logits,y_test,arr_pred_test,type_uncer,t,t_l,image_name,scal_fac=1e-9):\n",
    "    \n",
    "        aleo_list = []\n",
    "        for j in range(len(logits)):\n",
    "            prob_list = []\n",
    "            for i in range(logits[j].shape[1]):\n",
    "                arg = np.argmax(logits[j][:,i])\n",
    "                prob = logits[j][:,i][arg]\n",
    "                prob_list.append(prob)\n",
    "            aleo = list(np.array(prob_list) - np.square(np.array(prob_list)))\n",
    "            aleo_list.append(aleo)\n",
    "            \n",
    "        epi_list = []\n",
    "        for j in range(len(logits)):\n",
    "            prob_list = []\n",
    "            for i in range(logits[j].shape[1]):\n",
    "                arg = np.argmax(logits[j][:,i])\n",
    "                prob = logits[j][:,i][arg]\n",
    "                prob_list.append(prob)\n",
    "            epi_list.append(np.array(prob_list))\n",
    "        epistemic_uncertainty = np.mean(np.square((np.array(epi_list)-np.mean(np.array(epi_list),axis=0))),axis=0)\n",
    "        aleoteric_uncertainty = np.mean(np.array(aleo_list),axis=0)\n",
    "        \n",
    "        incorrect = []\n",
    "        for i in range(len(list(arr_pred_test))):\n",
    "            if (arr_pred_test[i] != np.array(y_test)[i]):\n",
    "                incorrect.append(i)\n",
    "                \n",
    "        list_aleoteric_correct = []\n",
    "        list_aleoteric_incorrect = []\n",
    "        for i in range(len(aleoteric_uncertainty)):\n",
    "            if (i in incorrect) == True:\n",
    "                list_aleoteric_incorrect.append(aleoteric_uncertainty[i])\n",
    "            if (i in incorrect) == False:\n",
    "                list_aleoteric_correct.append(aleoteric_uncertainty[i])\n",
    "                \n",
    "        list_epistemic_correct = []\n",
    "        list_epistemic_incorrect = []\n",
    "        for i in range(len(epistemic_uncertainty)):\n",
    "            if (i in incorrect) == True:\n",
    "                list_epistemic_incorrect.append(epistemic_uncertainty[i])\n",
    "            if (i in incorrect) == False:\n",
    "                list_epistemic_correct.append(epistemic_uncertainty[i])\n",
    "                \n",
    "        corr = np.mean(np.array(list_aleoteric_correct))\n",
    "        incorr = np.mean(np.array(list_aleoteric_incorrect))\n",
    "        corr_epistemic = np.mean(np.array(list_epistemic_correct))\n",
    "        incorr_epistemic = np.mean(np.array(list_epistemic_incorrect))\n",
    "        \n",
    "        if type_uncer == 'Aleatoric':\n",
    "            fig = plt.figure()\n",
    "            ax1 = fig.add_axes([0, 0, 1, 1])\n",
    "            ax2 = fig.add_axes()\n",
    "            ax2 = ax1.twinx()\n",
    "            ax1.tick_params(axis='y', labelcolor='b')\n",
    "            ax2.tick_params(axis='y', labelcolor='r')\n",
    "\n",
    "            \n",
    "            sns.kdeplot(list_aleoteric_correct,color='b',ax=ax1)\n",
    "            sns.kdeplot(list_aleoteric_incorrect,color='r',ax=ax2).set(xlim=(0, 0.35))\n",
    "   \n",
    "            if t == 'Train':\n",
    "                plt.axvline(x=corr,c= 'b',linestyle='--',label = 'Mean uncertainty (correct)')\n",
    "                plt.axvline(x=incorr, c = 'r',linestyle='--',label = 'Mean uncertainty (incorrect)')\n",
    "                \n",
    "           \n",
    "            \n",
    "            if t == 'Validation':\n",
    "                plt.axhline(y=corr,c= 'g',label='Mean uncertainty for correct predictions')\n",
    "                plt.axhline(y=incorr, c = 'm',label='Mean uncertainty for incorrect predictions')\n",
    "                plt.legend(bbox_to_anchor=(1,1),prop={'size':10})\n",
    "   \n",
    "            if t== 'Test':\n",
    "                plt.axvline(x=corr, c = 'b',linestyle='--',label= 'Mean test uncertainty (correct)')\n",
    "                plt.axvline(x=incorr,c= 'r',linestyle='--',label = 'Mean test uncertaity (incorrect)')\n",
    "                plt.axvline(x=t_l, c = 'g',linestyle='--',label = 'Mean train uncertainty (correct)')\n",
    "                \n",
    "            plt.legend(bbox_to_anchor=(1.6,1))    \n",
    "            \n",
    "                \n",
    "            ax1.set_ylabel('Density (Correct Predictions)', color='b',fontsize=15)\n",
    "            ax2.set_ylabel('Density (Incorrect Predictions)', color='r',fontsize=15)\n",
    "\n",
    "            ax1.set_xlabel('Aleatoric Uncertainty',fontsize = 15)\n",
    "           \n",
    "            plt.show()\n",
    "            return [aleoteric_uncertainty,corr,incorr]\n",
    "\n",
    "        if type_uncer == 'Epistemic':\n",
    "            fig = plt.figure()\n",
    "            ax1 = fig.add_axes([0, 0, 1, 1])\n",
    "            ax2 = fig.add_axes()\n",
    "            ax2 = ax1.twinx()\n",
    "            ax1.tick_params(axis='y', labelcolor='b')\n",
    "            ax2.tick_params(axis='y', labelcolor='r')\n",
    "           \n",
    "            \n",
    "            sns.kdeplot(np.array(list_epistemic_correct)/scal_fac,color='b',ax=ax1)\n",
    "            sns.kdeplot(np.array(list_epistemic_incorrect)/scal_fac,color='r',ax=ax2).set(xlim=(0, 2))\n",
    "   \n",
    "            if t == 'Train':\n",
    "                plt.axvline(x=corr_epistemic/scal_fac, c = 'b',linestyle='--',label = 'Mean uncertainty (correct)')\n",
    "                plt.axvline(x=incorr_epistemic/scal_fac,c= 'r',linestyle='--',label = 'Mean uncertainty (incorrect)')\n",
    "                \n",
    "   \n",
    "            if t== 'Test':\n",
    "                plt.axvline(x=corr_epistemic/scal_fac, c = 'b',linestyle='--',label = 'Mean test uncertainty (correct)')\n",
    "                plt.axvline(x=incorr_epistemic/scal_fac,c= 'r',linestyle='--',label = 'Mean test uncertainty (incorrect)')\n",
    "                plt.axvline(x=t_l*scal_fac, c = 'g',linestyle='--',label='Mean train uncertainty (correct)')\n",
    "                \n",
    "                \n",
    "            \n",
    "            plt.legend(bbox_to_anchor=(1.6,1))\n",
    "            \n",
    "            ax1.set_ylabel('Density (Correct Predictions)', color='b',fontsize=15)\n",
    "            ax2.set_ylabel('Density (Incorrect Predictions)', color='r',fontsize=15)\n",
    "            ax1.set_xlabel('Epistemic Uncertainty (x '+str(r'$10^{'+str(scal_fac).split('e')[-1]+'}$')+')',fontsize = 15)\n",
    "            \n",
    "            fig.savefig('Desktop/paper_revision/'+str(image_name)+'.pdf', format='pdf', dpi=1200,bbox_inches='tight')\n",
    "            plt.show()\n",
    "            return [epistemic_uncertainty,corr_epistemic,incorr_epistemic]\n",
    "\n",
    "\n",
    "def com_ep_un(logits,arg_passed='argmax'):        \n",
    "    epi_list = []\n",
    "    for j in range(len(logits)):\n",
    "        prob_list = []\n",
    "        for i in range(logits[j].shape[1]):\n",
    "            if arg_passed=='argmax':\n",
    "                arg = np.argmax(logits[j][:,i])\n",
    "            else:\n",
    "                arg = arg_passed\n",
    "            prob = logits[j][:,i][arg]\n",
    "            prob_list.append(prob)\n",
    "        epi_list.append(np.array(prob_list))\n",
    "        \n",
    "    epistemic_uncertainty = np.mean(np.square((np.array(epi_list)-np.mean(np.array(epi_list),axis=0))),axis=0)\n",
    "    \n",
    "    return epistemic_uncertainty\n",
    "\n",
    "\n",
    "\n",
    "def uncertainty_correction(test_logits):\n",
    "    \n",
    "    adjusted_logits_complete = []\n",
    "    mean_test_logits = sum(test_logits)/len(test_logits)\n",
    "    func_mean_test_logits = np.log(np.array(mean_test_logits)/(1-np.array(mean_test_logits)))\n",
    "    \n",
    "    \n",
    "    for index in range(test_logits[0].shape[0]):\n",
    "    \n",
    "       \n",
    "        epistemic_test = np.sqrt(com_ep_un(test_logits,index))\n",
    "        epistemic_test_norm = epistemic_test/np.max(epistemic_test)\n",
    "\n",
    "        X = epistemic_test_norm\n",
    "        Y = list(func_mean_test_logits[index,:])\n",
    "        X = sm.add_constant(X)\n",
    "        model = sm.OLS(Y, X).fit()\n",
    "        adj_logits = func_mean_test_logits[index,:]-model.params[1]*epistemic_test_norm\n",
    "        func_inv_adj_logits = np.exp(adj_logits)/(1+np.exp(adj_logits))\n",
    "        adjusted_logits_complete.append(func_inv_adj_logits)\n",
    "\n",
    "    return adjusted_logits_complete\n",
    "\n",
    "\n",
    "\n",
    "def uncertainty_analysis(logits_train,y_train,arr_pred_train,logits,y_test,arr_pred_test,scal_fac,analysis_type):\n",
    "    [al_train,mu_train_ac,mu_train_nac] = uncertainty_calculation(logits_train,y_train,arr_pred_train,'Aleatoric','Train',_,analysis_type)\n",
    "    [ep_train,mu_train_ec,mu_train_nec] = uncertainty_calculation(logits_train,y_train,arr_pred_train,'Epistemic','Train',_,analysis_type,scal_fac)\n",
    "    [al_test,mu_test_ac,mu_test_nac] = uncertainty_calculation(logits,y_test,arr_pred_test,'Aleatoric','Test',mu_train_ac,analysis_type)\n",
    "    [ep_test,mu_test_ec,mu_test_nec] = uncertainty_calculation(logits,y_test,arr_pred_test,'Epistemic','Test',mu_train_ec,analysis_type,scal_fac)\n",
    "    dict_numtrain_samples = Counter(np.array(y_train))\n",
    "    dict_numtest_samples = Counter(np.array(y_test))\n",
    "    dict_result_train = type_wise_results(dict_numtrain_samples,np.array(y_train),arr_pred_train,al_train,ep_train)\n",
    "    dict_result_test = type_wise_results(dict_numtest_samples,np.array(y_test),arr_pred_test,al_test,ep_test)\n",
    "    dict_result_train = type_wise_results(dict_numtrain_samples,np.array(y_train),arr_pred_train,al_train,ep_train)\n",
    "    dict_result_test = type_wise_results(dict_numtest_samples,np.array(y_test),arr_pred_test,al_test,ep_test)\n",
    "    #dict_mean_ep,dict_mean_test_corr,dict_mean_test_incorr = cancer_wise_uncertainty(dict_result_train,'Epistemic',np.array(y_test),arr_pred_test,ep_test,'epistemic_uncertainty_cancer_wise')\n",
    "    dict_mean_ep,dict_mean_test_corr,dict_mean_test_incorr = detailed_plot_new(dict_result_train,'Epistemic',np.array(y_test),arr_pred_test,ep_test,'epistemic_uncertainty_cancer_wise',cancer_types,1/scal_fac)\n",
    "    list_final_pred = []\n",
    "    list_final_test = []\n",
    "    uncertain = []\n",
    "    certain = []\n",
    "    for i in range(len(arr_pred_test)):\n",
    "        if (ep_test[i]/scal_fac <= dict_mean_ep[arr_pred_test[i]]):\n",
    "            list_final_test.append(np.array(y_test)[i])\n",
    "            list_final_pred.append(arr_pred_test[i])\n",
    "\n",
    "            certain.append(i)\n",
    "\n",
    "        else:\n",
    "            uncertain.append(i)\n",
    "            \n",
    "    start_index = 0\n",
    "    for i in range(logits[0].shape[0]):\n",
    "        print(i)\n",
    "        temp_index = Counter(y_test)[i]\n",
    "        end_index = start_index+temp_index\n",
    "        logits_temp = list(np.array(logits)[:,:,start_index:end_index])\n",
    "        adjusted_logits_temp = uncertainty_correction(logits_temp)\n",
    "        print(np.array(adjusted_logits_temp).shape)\n",
    "        if i == 0:\n",
    "            adjusted_logits_complete = np.array(adjusted_logits_temp)\n",
    "        else:\n",
    "            adjusted_logits_complete = np.concatenate((adjusted_logits_complete,np.array(adjusted_logits_temp)),axis=1)\n",
    "        start_index = end_index\n",
    "    res = adjusted_logits_complete\n",
    "    arr_pred_test_new = []\n",
    "    counter = 0\n",
    "    for i in range(logits[0].shape[1]):\n",
    "        if np.argmax(np.array(res)[:,i]) == list(y_test)[i]:\n",
    "            counter = counter+1\n",
    "        arr_pred_test_new.append(np.argmax(np.array(res)[:,i]))\n",
    "    \n",
    "    print('EpICC\\n')\n",
    "    print(accuracy_score(y_test,arr_pred_test_new))\n",
    "    print(np.mean(precision_recall_fscore_support(y_test,arr_pred_test_new)[1]))\n",
    "    print('Filtering\\n')\n",
    "    print(accuracy_score(list_final_test,list_final_pred))\n",
    "    print(np.mean(precision_recall_fscore_support(list_final_test,list_final_pred)[1]))\n",
    "    \n",
    "    fig = plt.figure()\n",
    "    for key in dict_mean_test_corr.keys():\n",
    "        if analysis_type != 'lgg_subtypes':\n",
    "            plt.bar(key-0.1,dict_mean_ep[key],width=0.05,color='green')\n",
    "            plt.bar(key,dict_mean_test_corr[key],width=0.05,color='blue')\n",
    "            plt.bar(key+0.1,dict_mean_test_incorr[key],width=0.05,color='red')\n",
    "        else:\n",
    "            plt.bar(key-0.2,dict_mean_ep[key],width=0.1,color='green')#,label='Correct train')\n",
    "            plt.bar(key,dict_mean_test_corr[key],width=0.1,color='blue')#,label='Correct test')\n",
    "            plt.bar(key+0.2,dict_mean_test_incorr[key],width=0.1,color='red')#,label = 'Incorrect test')\n",
    "    plt.ylabel('Mean Uncertainty (x'+str(r'$10^{'+str(scal_fac).split('e')[-1]+'}$')+')',fontsize = 15)\n",
    "    plt.xlabel(analysis_type.split('_')[0].upper()+' '+analysis_type.split('_')[1],fontsize=20)\n",
    "    plt.xticks(np.arange(0,len(cancer_types)),cancer_types,fontsize=15)\n",
    "    plt.legend(prop={'size':12})\n",
    "    ax = plt.gca()\n",
    "    ax.yaxis.grid(True,which='major')\n",
    "    fig.savefig('Desktop/paper_revision/uncert_comparison_'+analysis_type+'.pdf', format='pdf', dpi=1200,bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    return dict_mean_ep,dict_mean_test_corr,dict_mean_test_incorr,res,list_final_test,list_final_pred,arr_pred_test_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_train_test(df_pca2,rs):\n",
    "    for l in range(len(list(df_pca2['label'].unique()))):\n",
    "        df_temp = df_pca2.loc[df_pca2['label'] == l]\n",
    "        if l == 0:\n",
    "            X_train, X_test, y_train, y_test = train_test_split(df_temp.iloc[:,:-1],df_temp.iloc[:,-1], test_size=0.20, random_state=rs)\n",
    "        else:\n",
    "            X_train_temp, X_test_temp, y_train_temp, y_test_temp = train_test_split(df_temp.iloc[:,:-1],df_temp.iloc[:,-1], test_size=0.20, random_state=rs)\n",
    "            X_train = pd.concat([X_train,X_train_temp])\n",
    "            X_test = pd.concat([X_test,X_test_temp])\n",
    "            y_train = pd.concat([y_train,y_train_temp])\n",
    "            y_test = pd.concat([y_test,y_test_temp])\n",
    "    return (X_train, X_test, y_train, y_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_analysis = pd.read_csv('D:/Desktop/Study_Material/paper_figures/Manuscript/Figures_and_tables/Supplementary/Tables/2.csv')\n",
    "sample_numbers = list(df_analysis.iloc[1:,1])\n",
    "analysis_type = 'all_cancer_types'\n",
    "cancer_types = ['LAML','ACC','BLCA','LGG','BRCA','CESC','CHOL','COAD','UCEC','ESCA','GBM','HNSC','KIRC','KIRP','LIHC','LUAD','LUSC','DLBC','MESO','OV','PAAD','PCPG','PRAD','READ','SKCM','STAD','TGCT','THYM','THCA','UCS','UVM']\n",
    "df_pca2 = pd.read_csv('D:/New folder/100_genes_pca2_new.csv')\n",
    "(X_train, X_test, y_train, y_test) = split_train_test(df_pca2,r)\n",
    "Ytrain = np.array(y_train).reshape(len(y_train),)\n",
    "X_train = np.array(X_train.T.reset_index(drop=True))\n",
    "Y_train = tf.Session().run(tf.one_hot(Ytrain,len(set(Ytrain)),axis=1)).reshape(len(Ytrain),len(set(Ytrain))).T\n",
    "Ytest = np.array(y_test).reshape(len(y_test),)\n",
    "X_test = np.array(X_test.T.reset_index(drop=True))\n",
    "Y_test = tf.Session().run(tf.one_hot(Ytest,len(set(Ytest)),axis=1)).reshape(len(Ytest),len(set(Ytest))).T\n",
    "layers_dims = [X_train.shape[0],250,95,31]\n",
    "[_,_,logits,logits_train,arr_pred_test,arr_pred_train,grad_val] = model(X_train=X_train,Y_train=Y_train,X_test =X_test,Y_test = Y_test, learning_rate=0.0005,num_epochs=3500,print_cost=True,layers_dims = layers_dims)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_mean_ep,dict_mean_test_corr,dict_mean_test_incorr,res,list_final_test,list_final_pred,arr_pred_test_new = uncertainty_analysis(logits_train,y_train,arr_pred_train,logits,y_test,arr_pred_test,1e-9,analysis_type)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
